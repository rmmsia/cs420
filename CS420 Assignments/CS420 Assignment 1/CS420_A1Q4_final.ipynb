{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5niXr3T2K7d"
      },
      "source": [
        "### Question 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EXa6DRW2ZyV"
      },
      "source": [
        "#### Import relevant packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Sgf1XoAoC2X2"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX5zcJj-2kMD"
      },
      "source": [
        "#### (a) Load the dataset `citrus_leaves` from `tensorflow_datasets`. Split the dataset into 60% for training and 40% for testing [**2 points**]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ERbxg-O05C5A"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-16 16:30:52.144496: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
            "2024-02-16 16:30:52.144519: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
            "2024-02-16 16:30:52.144523: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
            "2024-02-16 16:30:52.144563: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2024-02-16 16:30:52.144577: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "## write your code here\n",
        "\n",
        "ds = tfds.load('citrus_leaves', split='train', as_supervised=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eOkqSP3X6gNz"
      },
      "outputs": [],
      "source": [
        "## write your code here to split data into 60% train 40% test\n",
        "\n",
        "train_size = int(0.6 * len(ds))\n",
        "test_size = len(ds) - train_size\n",
        "\n",
        "train_dataset = ds.take(train_size)\n",
        "test_dataset = ds.skip(train_size)\n",
        "\n",
        "train_dataset = tfds.as_numpy(train_dataset)\n",
        "test_dataset = tfds.as_numpy(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "K9vaCqKaup1w"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-16 16:30:52.204165: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
            "\t [[{{node Placeholder/_0}}]]\n",
            "2024-02-16 16:30:52.204430: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
            "\t [[{{node Placeholder/_0}}]]\n",
            "2024-02-16 16:30:52.212455: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
            "2024-02-16 16:30:52.341874: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
            "2024-02-16 16:30:52.354999: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [1]\n",
            "\t [[{{node Placeholder/_4}}]]\n",
            "2024-02-16 16:30:52.355269: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1]\n",
            "\t [[{{node Placeholder/_2}}]]\n"
          ]
        }
      ],
      "source": [
        "# prepare training data\n",
        "train_images = []\n",
        "train_labels = []\n",
        "\n",
        "for i in train_dataset:\n",
        "  train_images.append(i[0])\n",
        "  train_labels.append(i[1])\n",
        "\n",
        "# convert to numpy arrays\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "# prepare test data\n",
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "for i in test_dataset:\n",
        "  test_images.append(i[0])\n",
        "  test_labels.append(i[1])\n",
        "\n",
        "# convert to numpy arrays\n",
        "test_images = np.array(test_images)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# normalize the images\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa-fkHXkqbr4"
      },
      "source": [
        "#### (b) Build a dense ANN with at least one hidden layer with at least two nodes. You should try different hyper parameter configurations to get the best performing ANN. [**2 points**]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Rgef5Zf96kSo"
      },
      "outputs": [],
      "source": [
        "## write your code here to build your dense ANN\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Flatten(input_shape=(256, 256, 3)))    # input layer\n",
        "model.add(layers.Dense(512, activation=tf.nn.elu))   # hidden layer 1\n",
        "# model.add(layers.Dense(256, activation=tf.nn.leaky_relu))      # hidden layer 2\n",
        "# model.add(layers.Dense(64, activation=tf.nn.relu))\n",
        "model.add(layers.Dense(4, activation=tf.nn.softmax))    # output layer with 4 outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jpiyjS6rMVZ"
      },
      "source": [
        "#### (c) Answer the following questions: [**1 point**]\n",
        "\n",
        "What is the size of your output layer? [4]\n",
        "\n",
        "What is the activation function of your output layer? [SoftMax]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTrcDebWsg7J"
      },
      "source": [
        "#### (d) Compile and train your model [**2 points**]\n",
        "\n",
        "What is the loss function you use? [Cross Entropy]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "48c-cHC26pLN"
      },
      "outputs": [],
      "source": [
        "### write your code here to compile model\n",
        "\n",
        "model.compile(optimizer= tf.optimizers.legacy.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gxnIxTP6-PO",
        "outputId": "cc2f2ef9-4f39-4b46-b58e-26586ec3deb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-16 16:30:53.115130: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - ETA: 0s - loss: 216.7331 - accuracy: 0.3034"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-16 16:30:54.358782: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 2s 121ms/step - loss: 216.7331 - accuracy: 0.3034 - val_loss: 55.7471 - val_accuracy: 0.2689\n",
            "Epoch 2/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 22.4853 - accuracy: 0.3258 - val_loss: 34.2087 - val_accuracy: 0.2773\n",
            "Epoch 3/128\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 19.7027 - accuracy: 0.3511 - val_loss: 9.4177 - val_accuracy: 0.3908\n",
            "Epoch 4/128\n",
            "12/12 [==============================] - 1s 82ms/step - loss: 7.0614 - accuracy: 0.4157 - val_loss: 8.8472 - val_accuracy: 0.3529\n",
            "Epoch 5/128\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 6.5489 - accuracy: 0.3961 - val_loss: 2.9165 - val_accuracy: 0.3487\n",
            "Epoch 6/128\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 2.5618 - accuracy: 0.4410 - val_loss: 1.6308 - val_accuracy: 0.4790\n",
            "Epoch 7/128\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 1.4198 - accuracy: 0.5337 - val_loss: 2.1081 - val_accuracy: 0.3613\n",
            "Epoch 8/128\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 1.1959 - accuracy: 0.5337 - val_loss: 3.1555 - val_accuracy: 0.2983\n",
            "Epoch 9/128\n",
            "12/12 [==============================] - 1s 89ms/step - loss: 1.7374 - accuracy: 0.4522 - val_loss: 2.0537 - val_accuracy: 0.4160\n",
            "Epoch 10/128\n",
            "12/12 [==============================] - 1s 91ms/step - loss: 1.8743 - accuracy: 0.4466 - val_loss: 5.0298 - val_accuracy: 0.1218\n",
            "Epoch 11/128\n",
            "12/12 [==============================] - 1s 90ms/step - loss: 3.3086 - accuracy: 0.3933 - val_loss: 2.2655 - val_accuracy: 0.5042\n",
            "Epoch 12/128\n",
            "12/12 [==============================] - 1s 92ms/step - loss: 2.5502 - accuracy: 0.4242 - val_loss: 1.6892 - val_accuracy: 0.4160\n",
            "Epoch 13/128\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 1.1699 - accuracy: 0.5618 - val_loss: 1.1806 - val_accuracy: 0.5168\n",
            "Epoch 14/128\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 1.4613 - accuracy: 0.5084 - val_loss: 1.3559 - val_accuracy: 0.5756\n",
            "Epoch 15/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 1.0367 - accuracy: 0.6433 - val_loss: 0.9525 - val_accuracy: 0.6218\n",
            "Epoch 16/128\n",
            "12/12 [==============================] - 1s 89ms/step - loss: 0.8704 - accuracy: 0.6489 - val_loss: 1.0050 - val_accuracy: 0.6218\n",
            "Epoch 17/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.9670 - accuracy: 0.6067 - val_loss: 1.4965 - val_accuracy: 0.4748\n",
            "Epoch 18/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 1.6935 - accuracy: 0.4691 - val_loss: 1.8036 - val_accuracy: 0.4244\n",
            "Epoch 19/128\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 1.2532 - accuracy: 0.5646 - val_loss: 1.4770 - val_accuracy: 0.4244\n",
            "Epoch 20/128\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.9850 - accuracy: 0.6180 - val_loss: 0.9987 - val_accuracy: 0.6008\n",
            "Epoch 21/128\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.7620 - accuracy: 0.7022 - val_loss: 0.9811 - val_accuracy: 0.5672\n",
            "Epoch 22/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.6881 - accuracy: 0.7388 - val_loss: 0.9636 - val_accuracy: 0.5756\n",
            "Epoch 23/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.7586 - accuracy: 0.6826 - val_loss: 0.9437 - val_accuracy: 0.6303\n",
            "Epoch 24/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.8458 - accuracy: 0.6657 - val_loss: 1.0284 - val_accuracy: 0.5378\n",
            "Epoch 25/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.6766 - accuracy: 0.7331 - val_loss: 0.9083 - val_accuracy: 0.6008\n",
            "Epoch 26/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.6589 - accuracy: 0.7388 - val_loss: 0.7967 - val_accuracy: 0.6723\n",
            "Epoch 27/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.7239 - accuracy: 0.6882 - val_loss: 0.8773 - val_accuracy: 0.6513\n",
            "Epoch 28/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.6830 - accuracy: 0.7275 - val_loss: 1.2248 - val_accuracy: 0.5000\n",
            "Epoch 29/128\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.7276 - accuracy: 0.6938 - val_loss: 1.0496 - val_accuracy: 0.5924\n",
            "Epoch 30/128\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.8920 - accuracy: 0.6433 - val_loss: 0.9692 - val_accuracy: 0.6176\n",
            "Epoch 31/128\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.8961 - accuracy: 0.6517 - val_loss: 1.3079 - val_accuracy: 0.5000\n",
            "Epoch 32/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.8674 - accuracy: 0.6489 - val_loss: 0.9829 - val_accuracy: 0.5798\n",
            "Epoch 33/128\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.5322 - accuracy: 0.7893 - val_loss: 1.0369 - val_accuracy: 0.5672\n",
            "Epoch 34/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.5690 - accuracy: 0.7725 - val_loss: 0.9155 - val_accuracy: 0.6092\n",
            "Epoch 35/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.5645 - accuracy: 0.7865 - val_loss: 1.1240 - val_accuracy: 0.5420\n",
            "Epoch 36/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.6388 - accuracy: 0.7191 - val_loss: 0.8948 - val_accuracy: 0.6303\n",
            "Epoch 37/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.5453 - accuracy: 0.7837 - val_loss: 0.7958 - val_accuracy: 0.6555\n",
            "Epoch 38/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.5192 - accuracy: 0.8034 - val_loss: 1.2726 - val_accuracy: 0.5756\n",
            "Epoch 39/128\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.5922 - accuracy: 0.7781 - val_loss: 1.2095 - val_accuracy: 0.4916\n",
            "Epoch 40/128\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.6396 - accuracy: 0.7500 - val_loss: 1.0469 - val_accuracy: 0.6050\n",
            "Epoch 41/128\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.5940 - accuracy: 0.7669 - val_loss: 0.7541 - val_accuracy: 0.6639\n",
            "Epoch 42/128\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.5188 - accuracy: 0.7949 - val_loss: 0.8912 - val_accuracy: 0.6429\n",
            "Epoch 43/128\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.6676 - accuracy: 0.7275 - val_loss: 2.6783 - val_accuracy: 0.2563\n",
            "Epoch 44/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 1.3628 - accuracy: 0.5197 - val_loss: 1.7645 - val_accuracy: 0.5210\n",
            "Epoch 45/128\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 1.0023 - accuracy: 0.5955 - val_loss: 1.3365 - val_accuracy: 0.5630\n",
            "Epoch 46/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.9762 - accuracy: 0.6264 - val_loss: 0.9230 - val_accuracy: 0.6176\n",
            "Epoch 47/128\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.7677 - accuracy: 0.7022 - val_loss: 1.3831 - val_accuracy: 0.4916\n",
            "Epoch 48/128\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.7728 - accuracy: 0.7107 - val_loss: 1.2084 - val_accuracy: 0.5252\n",
            "Epoch 49/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.6836 - accuracy: 0.7303 - val_loss: 0.8164 - val_accuracy: 0.6849\n",
            "Epoch 50/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.7249 - accuracy: 0.7079 - val_loss: 0.8424 - val_accuracy: 0.6891\n",
            "Epoch 51/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.6937 - accuracy: 0.7360 - val_loss: 0.9903 - val_accuracy: 0.6471\n",
            "Epoch 52/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.7549 - accuracy: 0.7022 - val_loss: 0.9536 - val_accuracy: 0.6303\n",
            "Epoch 53/128\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.7061 - accuracy: 0.7275 - val_loss: 0.9106 - val_accuracy: 0.6387\n",
            "Epoch 54/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.5988 - accuracy: 0.7921 - val_loss: 0.8662 - val_accuracy: 0.6723\n",
            "Epoch 55/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.5951 - accuracy: 0.7893 - val_loss: 1.0398 - val_accuracy: 0.6261\n",
            "Epoch 56/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.6218 - accuracy: 0.7893 - val_loss: 0.8371 - val_accuracy: 0.6681\n",
            "Epoch 57/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.5882 - accuracy: 0.7893 - val_loss: 0.8624 - val_accuracy: 0.6345\n",
            "Epoch 58/128\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.5899 - accuracy: 0.8006 - val_loss: 0.8315 - val_accuracy: 0.6513\n",
            "Epoch 59/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.5829 - accuracy: 0.8034 - val_loss: 1.1278 - val_accuracy: 0.5504\n",
            "Epoch 60/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.8946 - accuracy: 0.6292 - val_loss: 1.0045 - val_accuracy: 0.6303\n",
            "Epoch 61/128\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.6417 - accuracy: 0.7556 - val_loss: 0.9692 - val_accuracy: 0.6261\n",
            "Epoch 62/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.6737 - accuracy: 0.7331 - val_loss: 1.1247 - val_accuracy: 0.5966\n",
            "Epoch 63/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.6916 - accuracy: 0.7219 - val_loss: 0.9243 - val_accuracy: 0.6218\n",
            "Epoch 64/128\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.5875 - accuracy: 0.7753 - val_loss: 1.1728 - val_accuracy: 0.5840\n",
            "Epoch 65/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.7251 - accuracy: 0.6994 - val_loss: 1.0719 - val_accuracy: 0.5630\n",
            "Epoch 66/128\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.8151 - accuracy: 0.6713 - val_loss: 0.8415 - val_accuracy: 0.6597\n",
            "Epoch 67/128\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.6212 - accuracy: 0.7725 - val_loss: 0.9085 - val_accuracy: 0.6176\n",
            "Epoch 68/128\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.5897 - accuracy: 0.7612 - val_loss: 1.1081 - val_accuracy: 0.5420\n",
            "Epoch 69/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.7424 - accuracy: 0.7275 - val_loss: 1.2192 - val_accuracy: 0.5420\n",
            "Epoch 70/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.6999 - accuracy: 0.6938 - val_loss: 1.0923 - val_accuracy: 0.5840\n",
            "Epoch 71/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.6389 - accuracy: 0.7669 - val_loss: 0.8205 - val_accuracy: 0.6471\n",
            "Epoch 72/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.5482 - accuracy: 0.8090 - val_loss: 0.7923 - val_accuracy: 0.6933\n",
            "Epoch 73/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.5118 - accuracy: 0.8258 - val_loss: 1.0121 - val_accuracy: 0.6134\n",
            "Epoch 74/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.6035 - accuracy: 0.7556 - val_loss: 0.8359 - val_accuracy: 0.6555\n",
            "Epoch 75/128\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.5325 - accuracy: 0.8090 - val_loss: 1.2204 - val_accuracy: 0.5588\n",
            "Epoch 76/128\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.5825 - accuracy: 0.7753 - val_loss: 0.9007 - val_accuracy: 0.6597\n",
            "Epoch 77/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.5138 - accuracy: 0.8062 - val_loss: 0.7924 - val_accuracy: 0.6807\n",
            "Epoch 78/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.5241 - accuracy: 0.8090 - val_loss: 0.8841 - val_accuracy: 0.6303\n",
            "Epoch 79/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.5407 - accuracy: 0.8090 - val_loss: 0.9402 - val_accuracy: 0.6134\n",
            "Epoch 80/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.5262 - accuracy: 0.7893 - val_loss: 1.0561 - val_accuracy: 0.5840\n",
            "Epoch 81/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.5365 - accuracy: 0.7865 - val_loss: 0.7699 - val_accuracy: 0.7059\n",
            "Epoch 82/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.4861 - accuracy: 0.8062 - val_loss: 0.8550 - val_accuracy: 0.6555\n",
            "Epoch 83/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.4754 - accuracy: 0.8287 - val_loss: 1.3255 - val_accuracy: 0.5420\n",
            "Epoch 84/128\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.5322 - accuracy: 0.8090 - val_loss: 0.7666 - val_accuracy: 0.6975\n",
            "Epoch 85/128\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.5084 - accuracy: 0.7949 - val_loss: 0.9761 - val_accuracy: 0.6261\n",
            "Epoch 86/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.6198 - accuracy: 0.7360 - val_loss: 1.0868 - val_accuracy: 0.5924\n",
            "Epoch 87/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.6018 - accuracy: 0.7444 - val_loss: 1.2116 - val_accuracy: 0.5462\n",
            "Epoch 88/128\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.6512 - accuracy: 0.7416 - val_loss: 1.7809 - val_accuracy: 0.4622\n",
            "Epoch 89/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.9886 - accuracy: 0.6376 - val_loss: 1.7492 - val_accuracy: 0.4958\n",
            "Epoch 90/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.7152 - accuracy: 0.7303 - val_loss: 1.1251 - val_accuracy: 0.5966\n",
            "Epoch 91/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.5951 - accuracy: 0.7781 - val_loss: 1.5942 - val_accuracy: 0.4958\n",
            "Epoch 92/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 1.0409 - accuracy: 0.6152 - val_loss: 1.0964 - val_accuracy: 0.5840\n",
            "Epoch 93/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.7223 - accuracy: 0.6966 - val_loss: 1.0190 - val_accuracy: 0.6092\n",
            "Epoch 94/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.5333 - accuracy: 0.7781 - val_loss: 0.8344 - val_accuracy: 0.6723\n",
            "Epoch 95/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.4602 - accuracy: 0.8174 - val_loss: 0.7545 - val_accuracy: 0.6933\n",
            "Epoch 96/128\n",
            "12/12 [==============================] - 1s 87ms/step - loss: 0.4996 - accuracy: 0.8090 - val_loss: 0.7661 - val_accuracy: 0.6681\n",
            "Epoch 97/128\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.4965 - accuracy: 0.8034 - val_loss: 0.8358 - val_accuracy: 0.6429\n",
            "Epoch 98/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.4327 - accuracy: 0.8511 - val_loss: 1.0050 - val_accuracy: 0.6134\n",
            "Epoch 99/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.4811 - accuracy: 0.8034 - val_loss: 0.7442 - val_accuracy: 0.6891\n",
            "Epoch 100/128\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.4356 - accuracy: 0.8315 - val_loss: 0.8908 - val_accuracy: 0.6387\n",
            "Epoch 101/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.4889 - accuracy: 0.8118 - val_loss: 0.8769 - val_accuracy: 0.6723\n",
            "Epoch 102/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.3991 - accuracy: 0.8539 - val_loss: 0.7798 - val_accuracy: 0.6807\n",
            "Epoch 103/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.4947 - accuracy: 0.7978 - val_loss: 1.0076 - val_accuracy: 0.6134\n",
            "Epoch 104/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.5352 - accuracy: 0.7837 - val_loss: 1.1300 - val_accuracy: 0.6008\n",
            "Epoch 105/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.4421 - accuracy: 0.8287 - val_loss: 0.7798 - val_accuracy: 0.6639\n",
            "Epoch 106/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.4334 - accuracy: 0.8343 - val_loss: 1.3772 - val_accuracy: 0.5504\n",
            "Epoch 107/128\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.6203 - accuracy: 0.7416 - val_loss: 1.1413 - val_accuracy: 0.5756\n",
            "Epoch 108/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.5121 - accuracy: 0.7893 - val_loss: 0.7376 - val_accuracy: 0.6975\n",
            "Epoch 109/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.4154 - accuracy: 0.8455 - val_loss: 0.9645 - val_accuracy: 0.6261\n",
            "Epoch 110/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.3946 - accuracy: 0.8455 - val_loss: 0.7312 - val_accuracy: 0.7059\n",
            "Epoch 111/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.3727 - accuracy: 0.8427 - val_loss: 0.7708 - val_accuracy: 0.6723\n",
            "Epoch 112/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.4253 - accuracy: 0.8174 - val_loss: 0.8818 - val_accuracy: 0.6723\n",
            "Epoch 113/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.4357 - accuracy: 0.8287 - val_loss: 0.7413 - val_accuracy: 0.6639\n",
            "Epoch 114/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.3652 - accuracy: 0.8652 - val_loss: 0.7583 - val_accuracy: 0.7059\n",
            "Epoch 115/128\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.3760 - accuracy: 0.8539 - val_loss: 0.7138 - val_accuracy: 0.7101\n",
            "Epoch 116/128\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.3578 - accuracy: 0.8539 - val_loss: 0.7357 - val_accuracy: 0.7059\n",
            "Epoch 117/128\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.3612 - accuracy: 0.8736 - val_loss: 0.7353 - val_accuracy: 0.6933\n",
            "Epoch 118/128\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.4192 - accuracy: 0.8118 - val_loss: 1.6633 - val_accuracy: 0.4958\n",
            "Epoch 119/128\n",
            "12/12 [==============================] - 1s 87ms/step - loss: 0.7579 - accuracy: 0.6966 - val_loss: 0.9704 - val_accuracy: 0.6513\n",
            "Epoch 120/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.5931 - accuracy: 0.7275 - val_loss: 2.6359 - val_accuracy: 0.3571\n",
            "Epoch 121/128\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.8808 - accuracy: 0.6685 - val_loss: 0.9069 - val_accuracy: 0.6723\n",
            "Epoch 122/128\n",
            "12/12 [==============================] - 1s 90ms/step - loss: 0.4604 - accuracy: 0.7893 - val_loss: 0.8415 - val_accuracy: 0.6681\n",
            "Epoch 123/128\n",
            "12/12 [==============================] - 1s 87ms/step - loss: 0.3803 - accuracy: 0.8567 - val_loss: 0.9252 - val_accuracy: 0.6345\n",
            "Epoch 124/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.4268 - accuracy: 0.8174 - val_loss: 1.0381 - val_accuracy: 0.6176\n",
            "Epoch 125/128\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.4863 - accuracy: 0.7865 - val_loss: 0.7179 - val_accuracy: 0.7101\n",
            "Epoch 126/128\n",
            "12/12 [==============================] - 1s 89ms/step - loss: 0.3354 - accuracy: 0.8624 - val_loss: 0.8242 - val_accuracy: 0.6849\n",
            "Epoch 127/128\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.3722 - accuracy: 0.8427 - val_loss: 1.0565 - val_accuracy: 0.6555\n",
            "Epoch 128/128\n",
            "12/12 [==============================] - 1s 89ms/step - loss: 0.4191 - accuracy: 0.8343 - val_loss: 0.7384 - val_accuracy: 0.7269\n"
          ]
        }
      ],
      "source": [
        "### write your code here to train your model\n",
        "epochs = 128\n",
        "history = model.fit(train_images, train_labels, validation_data=(test_images, test_labels), epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx80XJHjw2vI"
      },
      "source": [
        "#### (e) Plot the training loss across the different epochs [**1 point**]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "2olEF8NB6r3H",
        "outputId": "dc26fd30-c070-4c5e-8349-0abd226ed11e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x134a52c50>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "### write your code here to plot loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx3JLnhQyQLZ"
      },
      "source": [
        "#### (f) What is the overall accuracy and per-class accuracy on test dataset? [**2 points**]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLQhrX4F6t2w",
        "outputId": "eca4d472-b0b3-4524-bb0f-405c5d495fb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7384 - accuracy: 0.7269\n"
          ]
        }
      ],
      "source": [
        "#### write your code to report overall accuracy on test set\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm9unSC26ag1"
      },
      "source": [
        "What is the overall accuracy? [72.69%]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "31X-0hsw6v_n"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Black spot: 54.69%\n",
            "canker: 85.48%\n",
            "greening: 85.71%\n",
            "healthy: 33.33%\n"
          ]
        }
      ],
      "source": [
        "### write your code to report per-class accuracy\n",
        "### you should have a list where index is the class label with value corresponding to accuracy for that class label\n",
        "\n",
        "# class names\n",
        "num_classes = 4\n",
        "class_names = ['Black spot', 'canker', 'greening', 'healthy']\n",
        "\n",
        "# Initialize counters as numpy arrays\n",
        "correct_predictions = np.zeros(num_classes, dtype=int)\n",
        "total_predictions = np.zeros(num_classes, dtype=int)\n",
        "\n",
        "# calculate per-class accuracy\n",
        "for i in range(len(test_images)):\n",
        "  prediction = model.predict(test_images[i].reshape(1, 256, 256, 3))\n",
        "  predicted_label = np.argmax(prediction)\n",
        "  actual_label = test_labels[i]\n",
        "\n",
        "  if predicted_label == actual_label:\n",
        "    correct_predictions[actual_label] += 1\n",
        "  total_predictions[actual_label] += 1\n",
        "\n",
        "per_class_accuracy = correct_predictions / total_predictions\n",
        "\n",
        "# print('Per-class accuracy:', per_class_accuracy)\n",
        "\n",
        "# print per-class accuracy with class names correct to 2 decimal places\n",
        "for i in range(num_classes):\n",
        "  print(f'{class_names[i]}: {per_class_accuracy[i] * 100:.2f}%')\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
